{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Goal of this tutorial is to showcase how to retrieve information from PDF papers, including both images and textual information.\n",
    "- The extracted data will be stored to a vector database (ChromaDB) \n",
    "- The agent will provide literature informed answers to human questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to run the tutorial you need to have and OPENAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"\" # Your OpenAI API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to download the pretrained weights of the YOLO model for image cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder for downloading the checkpoints from google cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.24.3\n",
      "PyTorch version: 2.0.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matagen.agents import *\n",
    "from matagen.scraping.pdf_scraper import pdf_scraper_tool\n",
    "from matagen.config.settings import OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file_path = \"DataMiningAgents/data/pdf_examples\"\n",
    "output_base_dir = \"outputs/\"\n",
    "pdf_scraper_tool(pdf_file_path, output_base_dir, paper_name=\"pdf_papers\", api_key = OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheme 1. Synthetic procedure of 4T/PEO4.\n",
      "outputs\\pdf_papers\\images_folder\\page_2_img_1_0.jpg\n",
      "POM image of 4T/PEO4-LiTFSI complex (r = 0.05) on cooling from isotropic melt at 97 and 50 °C (scale bar: 100 μm).\n",
      "outputs\\pdf_papers\\images_folder\\page_3_img_1_f.jpg\n",
      "POM image of pristine 4T/PEO4 (r = 0) on cooling from isotropic melt at 95 and 60 °C.\n",
      "outputs\\pdf_papers\\images_folder\\page_3_img_1_b.jpg\n",
      "POM image of 4T/PEO4-LiTFSI complex (r = 0.01) on cooling from isotropic melt at 75 and 40 °C.\n",
      "outputs\\pdf_papers\\images_folder\\page_3_img_1_d.jpg\n",
      "First cooling scans (indicated by black arrows) and second subsequent heating scans (indicated by red arrows) of 4T/PEO-LiTFSI complexes (r = 0, r = 0.01, r = 0.05).\n",
      "outputs\\pdf_papers\\images_folder\\page_3_img_1_a.jpg\n",
      "POM image of 4T/PEO4-LiTFSI complex (r = 0.05) on cooling from isotropic melt at 97 and 50 °C (scale bar: 100 μm).\n",
      "outputs\\pdf_papers\\images_folder\\page_3_img_1_g.jpg\n",
      "POM image of pristine 4T/PEO4 (r = 0) on cooling from isotropic melt at 95 and 60 °C.\n",
      "outputs\\pdf_papers\\images_folder\\page_3_img_1_c.jpg\n",
      "POM image of 4T/PEO4-LiTFSI complex (r = 0.01) on cooling from isotropic melt at 75 and 40 °C.\n",
      "outputs\\pdf_papers\\images_folder\\page_3_img_1_e.jpg\n",
      "[]\n",
      "outputs\\pdf_papers\\images_folder\\page_4_img_1_a.jpg\n",
      "Thin film of 4T/PEO4-LiTFSI complex (r = 0.01) at 25 °C (after annealed)\n",
      "outputs\\pdf_papers\\images_folder\\page_5_img_1_f.jpg\n",
      "Thin film of pristine 4T/PEO4 compound (r = 0) at 123 °C (during heating)\n",
      "outputs\\pdf_papers\\images_folder\\page_5_img_1_b.jpg\n",
      "Thin film of 4T/PEO4-LiTFSI complex (r = 0.05) at 123 °C (during heating)\n",
      "outputs\\pdf_papers\\images_folder\\page_5_img_1_h.jpg\n",
      "Thin film of pristine 4T/PEO4 compound (r = 0) at 25 °C (after annealed)\n",
      "outputs\\pdf_papers\\images_folder\\page_5_img_1_c.jpg\n",
      "Thin film of 4T/PEO4-LiTFSI complex (r = 0.01) at 25 °C (as-cast)\n",
      "outputs\\pdf_papers\\images_folder\\page_5_img_1_d.jpg\n",
      "Thin film of pristine 4T/PEO4 compound (r = 0) at 25 °C (as-cast)\n",
      "outputs\\pdf_papers\\images_folder\\page_5_img_1_a.jpg\n",
      "Thin film of 4T/PEO4-LiTFSI complex (r = 0.05) at 25 °C (as-cast)\n",
      "outputs\\pdf_papers\\images_folder\\page_5_img_1_g.jpg\n",
      "Thin film of 4T/PEO4-LiTFSI complex (r = 0.01) at 123 °C (during heating)\n",
      "outputs\\pdf_papers\\images_folder\\page_5_img_1_e.jpg\n",
      "Vertical linecuts of (00h) spot sequence for 4T/PEO4-LiTFSI complexes at different temperatures for r = 0.05 during each heating process.\n",
      "outputs\\pdf_papers\\images_folder\\page_6_img_1_c.jpg\n",
      "Vertical linecuts of (00h) spot sequence for 4T/PEO4-LiTFSI complexes at different temperatures for r = 0.01 during each heating process.\n",
      "outputs\\pdf_papers\\images_folder\\page_6_img_1_b.jpg\n",
      "Vertical linecuts of (00h) spot sequence for 4T/PEO4-LiTFSI complexes at different temperatures for r = 0 during each heating process.\n",
      "outputs\\pdf_papers\\images_folder\\page_6_img_1_a.jpg\n",
      "Vertical linecuts of (00h) spot sequence for 4T/PEO4-LiTFSI complexes at different temperatures for r = 0.01 during each cooling process.\n",
      "outputs\\pdf_papers\\images_folder\\page_6_img_1_e.jpg\n",
      "Vertical linecuts of (00h) spot sequence for 4T/PEO4-LiTFSI complexes at different temperatures for r = 0.05 during each cooling process.\n",
      "outputs\\pdf_papers\\images_folder\\page_6_img_1_f.jpg\n",
      "Vertical linecuts of (00h) spot sequence for 4T/PEO4-LiTFSI complexes at different temperatures for r = 0 during each cooling process.\n",
      "outputs\\pdf_papers\\images_folder\\page_6_img_1_d.jpg\n",
      "[]\n",
      "outputs\\pdf_papers\\images_folder\\page_7_img_1_a.jpg\n",
      "[]\n",
      "outputs\\pdf_papers\\images_folder\\page_7_img_1_e.jpg\n",
      "[]\n",
      "outputs\\pdf_papers\\images_folder\\page_7_img_1_d.jpg\n",
      "[]\n",
      "outputs\\pdf_papers\\images_folder\\page_7_img_1_c.jpg\n",
      "Sphericity of PEO4 chains from simulation\n",
      "outputs\\pdf_papers\\images_folder\\page_8_img_1_b.jpg\n",
      "Ionic conductivities of LiTFSI-blended 4T/PEO4 thin film at r = 0.01 and r = 0.05 as a function of temperature during heating and cooling processes. The gray-shaded area indicates the order–disorder transition regime.\n",
      "outputs\\pdf_papers\\images_folder\\page_9_img_1_b.jpg\n",
      "Optical microscope image of an interdigitated gold electrode device (IDE) used for ionic conductivity measurement\n",
      "outputs\\pdf_papers\\images_folder\\page_9_img_1_a.jpg\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor board to visualize the image-text pairs\n",
    "data = r\"outputs\\pdf_papers\\retrieved_image_caption_pairs.json\"\n",
    "import json\n",
    "data_dict = json.load(open(data, \"r\"))\n",
    "\n",
    "for i in data_dict[\"records\"]:\n",
    "    print(i['caption'])\n",
    "    print(i['image'])\n",
    "    print(i[\"caption_summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.modeling_utils because of the following error (look up to see its traceback):\nmodule 'torch' has no attribute 'compiler'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kvriz\\miniconda3\\envs\\mmatagen\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1967\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   1966\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1967\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kvriz\\miniconda3\\envs\\mmatagen\\Lib\\importlib\\__init__.py:126\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m    125\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1204\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1176\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1147\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:690\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:940\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:241\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kvriz\\miniconda3\\envs\\mmatagen\\Lib\\site-packages\\transformers\\modeling_utils.py:63\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mintegrations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mflash_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m flash_attention_forward\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mintegrations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mflex_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m flex_attention_forward\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mintegrations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msdpa_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sdpa_attention_forward\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kvriz\\miniconda3\\envs\\mmatagen\\Lib\\site-packages\\transformers\\integrations\\flex_attention.py:44\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mattention\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mflex_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     40\u001b[39m         create_block_mask \u001b[38;5;28;01mas\u001b[39;00m create_block_causal_mask_flex,\n\u001b[32m     41\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mWrappedFlexAttention\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\"\u001b[39;49;00m\n\u001b[32m     46\u001b[39m \u001b[33;43;03m    We are doing a singleton class so that flex attention is compiled once when it's first called.\u001b[39;49;00m\n\u001b[32m     47\u001b[39m \u001b[33;43;03m    \"\"\"\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kvriz\\miniconda3\\envs\\mmatagen\\Lib\\site-packages\\transformers\\integrations\\flex_attention.py:59\u001b[39m, in \u001b[36mWrappedFlexAttention\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._instance\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[38;5;129m@torch\u001b[39m\u001b[43m.\u001b[49m\u001b[43mcompiler\u001b[49m.disable(recursive=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, training):\n\u001b[32m     61\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[33;03m    Initialize or update the singleton instance.\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: module 'torch' has no attribute 'compiler'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m embedding_functions\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43membedding_functions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSentenceTransformerEmbeddingFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_embedding_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kvriz\\miniconda3\\envs\\mmatagen\\Lib\\site-packages\\chromadb\\utils\\embedding_functions\\sentence_transformer_embedding_function.py:29\u001b[39m, in \u001b[36mSentenceTransformerEmbeddingFunction.__init__\u001b[39m\u001b[34m(self, model_name, device, normalize_embeddings, **kwargs)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Initialize SentenceTransformerEmbeddingFunction.\u001b[39;00m\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m \u001b[33;03m    **kwargs: Additional arguments to pass to the SentenceTransformer model.\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     32\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe sentence_transformers python package is not installed. Please install it with `pip install sentence_transformers`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     33\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kvriz\\miniconda3\\envs\\mmatagen\\Lib\\site-packages\\sentence_transformers\\__init__.py:14\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     export_dynamic_quantized_onnx_model,\n\u001b[32m     11\u001b[39m     export_optimized_onnx_model,\n\u001b[32m     12\u001b[39m     export_static_quantized_openvino_model,\n\u001b[32m     13\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcross_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     15\u001b[39m     CrossEncoder,\n\u001b[32m     16\u001b[39m     CrossEncoderModelCardData,\n\u001b[32m     17\u001b[39m     CrossEncoderTrainer,\n\u001b[32m     18\u001b[39m     CrossEncoderTrainingArguments,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mLoggingHandler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kvriz\\miniconda3\\envs\\mmatagen\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mCrossEncoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_card\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainer\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kvriz\\miniconda3\\envs\\mmatagen\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautonotebook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m trange\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     AutoConfig,\n\u001b[32m     17\u001b[39m     AutoModelForSequenceClassification,\n\u001b[32m     18\u001b[39m     AutoTokenizer,\n\u001b[32m     19\u001b[39m     PretrainedConfig,\n\u001b[32m     20\u001b[39m     PreTrainedModel,\n\u001b[32m     21\u001b[39m )\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PushToHubMixin\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deprecated\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1229\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kvriz\\miniconda3\\envs\\mmatagen\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1955\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1953\u001b[39m     value = Placeholder\n\u001b[32m   1954\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._class_to_module.keys():\n\u001b[32m-> \u001b[39m\u001b[32m1955\u001b[39m     module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1956\u001b[39m     value = \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[32m   1957\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._modules:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kvriz\\miniconda3\\envs\\mmatagen\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1969\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   1967\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib.import_module(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m + module_name, \u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m)\n\u001b[32m   1968\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1969\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1970\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m because of the following error (look up to see its\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1971\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1972\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Failed to import transformers.modeling_utils because of the following error (look up to see its traceback):\nmodule 'torch' has no attribute 'compiler'"
     ]
    }
   ],
   "source": [
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "embedding_functions.SentenceTransformerEmbeddingFunction(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ChromaDB Population (Text Chunks + Image Captions)\n",
      "Script directory: c:\\Users\\kvriz\\Desktop\\DataMiningAgents\\notebooks\n",
      "Resolved paths:\n",
      "  Outputs folder: outputs/pdf_papers\n",
      "  JSON file path: outputs/pdf_papers\\retrieved_image_caption_pairs.json\n",
      "  Text folder path: outputs/pdf_papers\\pdf\n",
      "  ChromaDB storage path: c:\\Users\\kvriz\\Desktop\\DataMiningAgents\\notebooks\\./my_multimodal_chroma_db\n",
      "\n",
      "--- Loading Source Data ---\n",
      "Successfully loaded 30 image records from outputs/pdf_papers\\retrieved_image_caption_pairs.json\n",
      "Finished finding 1 text files.\n",
      "Finished chunking 1 text files.\n",
      "\n",
      "--- Preparing Documents from Image Captions (30 records) ---\n",
      "Finished preparing 30 documents from image captions.\n",
      "\n",
      "--- Initializing ChromaDB ---\n",
      "Using persistent storage at: c:\\Users\\kvriz\\Desktop\\DataMiningAgents\\notebooks\\./my_multimodal_chroma_db\n",
      "\n",
      "Setting up TEXT embedding function: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kvriz\\miniconda3\\envs\\mmatagen\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading text embedding function model 'all-MiniLM-L6-v2': Failed to import transformers.modeling_utils because of the following error (look up to see its traceback):\n",
      "module 'torch' has no attribute 'compiler'\n",
      "Will attempt to use ChromaDB default.\n",
      "\n",
      "Accessing collection: 'multimodal_rag_collection'\n",
      "DEBUG: Embedding function being used: None\n",
      "Collection 'multimodal_rag_collection' ready (using text embeddings).\n",
      "\n",
      "--- Adding Data to ChromaDB Collection ---\n",
      "\n",
      "Preparing 99 total text documents (chunks + image captions) for batch addition...\n",
      "Adding data in 1 batches of size 500...\n",
      "  Adding batch 1/1 (99 items)...\n",
      "  Error during batch 1 upsert: You must provide an embedding function to compute embeddings.https://docs.trychroma.com/guides/embeddings in upsert.\n",
      "\n",
      "Finished adding/updating 99 text documents.\n",
      "\n",
      "--- Script Finished ---\n",
      "Collection 'multimodal_rag_collection' now contains 0 items.\n",
      "Total execution time: 8.42 seconds\n",
      "ChromaDB data is stored in: c:\\Users\\kvriz\\Desktop\\DataMiningAgents\\notebooks\\./my_multimodal_chroma_db\n"
     ]
    }
   ],
   "source": [
    "# Use the multimodal information to create a RAG Agent\n",
    "from matagen.analysis import multimodal_db\n",
    "outputs_folder = \"outputs/pdf_papers\"\n",
    "json_file_name = \"retrieved_image_caption_pairs.json\"  # Name of the JSON file inside OUTPUTS_FOLDER\n",
    "text_folder_name = \"pdf\"      # Name of the subfolder with the retrieved text from the PDF file\n",
    "chroma_db_path = \"./my_multimodal_chroma_db\" # Directory to store the persistent ChromaDB database\n",
    "collection_name = \"multimodal_rag_collection\" # Name for the ChromaDB collection\n",
    "text_embedding_model = \"all-MiniLM-L6-v2\" # Standard good default\n",
    "\n",
    "multimodal_db.create_multimodal_chromadb(outputs_folder, json_file_name, text_folder_name, chroma_db_path, collection_name, text_embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the multimodal database\n",
    "from matagen.agents.multimodal_rag_agent import MultimodalAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmatagen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
